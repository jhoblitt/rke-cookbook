operatorNamespace: rook-ceph

toolbox:
  enabled: true
  image: rook/ceph:v1.6.6
  tolerations:
    - key: node.kubernetes.io/unreachable
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 5
    - key: role
      operator: Equal
      value: storage-node
      effect: NoSchedule
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: role
              operator: In
              values:
                - storage-node

monitoring:
  enabled: true
  rulesNamespaceOverride: rook-ceph

cephClusterSpec:
  cephVersion:
    image: ceph/ceph:v16.2.4
    allowUnsupported: false
  dataDirHostPath: /var/lib/rook
  skipUpgradeChecks: false
  continueUpgradeAfterChecksEvenIfNotHealthy: false
  waitTimeoutForHealthyOSDInMinutes: 10
  mon:
    count: 3
    allowMultiplePerNode: false
  mgr:
    count: 2
    modules:
      - name: pg_autoscaler
        enabled: true
  dashboard:
    enabled: true
    ssl: true
  crashCollector:
    disable: false
  logCollector:
    enabled: true
    periodicity: 30d # SUFFIX may be 'h' for hours or 'd' for days.
  cleanupPolicy:
    #confirmation: "yes-really-destroy-data"
    sanitizeDisks:
      method: quick
      dataSource: zero
      iteration: 1
    allowUninstallWithVolumes: false
  placement:
    all:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: role
              operator: In
              values:
              - storage-node
      tolerations:
      - key: role
        operator: Equal
        value: storage-node
        effect: NoSchedule
  resources:
  # The requests and limits set here, allow the mgr pod to use half of one CPU core and 1 gigabyte of memory
  #    mgr:
  #      limits:
  #        cpu: "500m"
  #        memory: "1024Mi"
  #      requests:
  #        cpu: "500m"
  #        memory: "1024Mi"
  # The above example requests/limits can also be added to the other components
  #    mon:
  #    osd:
  #    prepareosd:
  #    mgr-sidecar:
  #    crashcollector:
  #    logcollector:
  #    cleanup:
  # The option to automatically remove OSDs that are out and are safe to destroy.
  removeOSDsIfOutAndSafeToRemove: false
  #  priorityClassNames:
  #    all: rook-ceph-default-priority-class
  #    mon: rook-ceph-mon-priority-class
  #    osd: rook-ceph-osd-priority-class
  #    mgr: rook-ceph-mgr-priority-class
  storage:
    useAllNodes: false
    useAllDevices: false
    config:
      osdsPerDevice: "4"
    nodes:
    - name: pillan01
      devices:
      - name: /dev/disk/by-id/nvme-Samsung_SSD_983_DCT_1.92TB_S48BNG0MB01685F
    - name: pillan02
      devices:
      - name: /dev/disk/by-id/nvme-Samsung_SSD_983_DCT_1.92TB_S48BNG0MB01695D
    - name: pillan03
      devices:
      - name: /dev/disk/by-id/nvme-Samsung_SSD_983_DCT_1.92TB_S48BNG0MB01690H
  disruptionManagement:
    managePodBudgets: true
    osdMaintenanceTimeout: 30
    pgHealthCheckTimeout: 30
    manageMachineDisruptionBudgets: false
  healthCheck:
    daemonHealth:
      mon:
        disabled: false
        interval: 45s
      osd:
        disabled: false
        interval: 60s
      status:
        disabled: false
        interval: 60s
    livenessProbe:
      mon:
        disabled: false
      mgr:
        disabled: false
      osd:
        disabled: false
